/**

@page viterbi_manual viterbi
@brief *Combine n-gram model and likelihoods to estimate posterior probabilities*
@tableofcontents

@section synopsis Synopsis

@SYNOPSIS@

`viterbi` is a simple time-synchronous Viterbi decoder. It finds the
most likely sequence of items drawn from a fixed vocabulary, given
frame-by-frame observation probabilities for each item in that
vocabulary, and a ngram grammar. Possible uses include:

  - Simple speech recogniser back end

`viterbi` can optionally use two sets of frame-by-frame observation
probabilities in a weighted-sum fashion. Also, the ngram language model
is not restricted to the conventional sliding window type in which the
previous n-1 items are the ngram context. Items in the ngram context
at each frame may be given. In this case, the user must provide a file
containing the ngram context: one (n-1) tuple per line. To include
items from the partial Viterbi path so far (i.e. found at recognition
time, not given) the special notation `<-N>` is used where N indicates
the distance back to the item required. For example `<-1>` would
indicate the item on the partial Viterbi path at the last frame. See
\ref viterbi-examples.

**Pruning**

Three types of pruning are available to reduce the size of the search
space and therefore speed up the search:

  - Observation pruning
  - Top-N pruning at each frame
  - Fixed width beam pruning

@section options Options

@OPTIONS@

@section viterbi-examples Examples

Example 'given' file (items f and g are in the vocabulary), the ngram
is a 4-gram.

    <-2> g g
    <-1> g f
    <-1> f g
    <-2> g g
    <-3> g g
    <-1> g f

*/
