<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/loose.dtd">
<HTML
><HEAD
><TITLE
>Building letter-to-sound rules automatically</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.79"><LINK
REL="HOME"
TITLE="Building Synthetic Voices"
HREF="book1.html"><LINK
REL="UP"
TITLE="Lexicons"
HREF="c1379.html"><LINK
REL="PREVIOUS"
TITLE="Building letter-to-sound rules by hand"
HREF="x1429.html"><LINK
REL="NEXT"
TITLE="Post-lexical rules"
HREF="x1615.html"></HEAD
><BODY
CLASS="SECT1"
BGCOLOR="#FFFFFF"
TEXT="#000000"
LINK="#0000FF"
VLINK="#840084"
ALINK="#0000FF"
><DIV
CLASS="NAVHEADER"
><TABLE
SUMMARY="Header navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TH
COLSPAN="3"
ALIGN="center"
>Building Synthetic Voices</TH
></TR
><TR
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="bottom"
><A
HREF="x1429.html"
ACCESSKEY="P"
>&#60;&#60;&#60; Previous</A
></TD
><TD
WIDTH="80%"
ALIGN="center"
VALIGN="bottom"
>Lexicons</TD
><TD
WIDTH="10%"
ALIGN="right"
VALIGN="bottom"
><A
HREF="x1615.html"
ACCESSKEY="N"
>Next &#62;&#62;&#62;</A
></TD
></TR
></TABLE
><HR
ALIGN="LEFT"
WIDTH="100%"></DIV
><DIV
CLASS="SECT1"
><H1
CLASS="SECT1"
><A
NAME="AEN1469"
>Building letter-to-sound rules automatically</A
></H1
><P
>For some languages the writing of a rule system is too difficult. 
Although there have been many valiant attempts to do so for languages 
like English life is basically too short to do this. Therefore we also 
include a method for automatically building LTS rules sets for a lexicon 
of pronunciations. This technique has successfully been used from 
English (British and American), French and German. The difficulty and 
appropriateness of using letter-to-sound rules is very language 
dependent, </P
><P
>The following outlines the processes involved in building a letter to 
sound model for a language given a large lexicon of pronunciations. 
This technique is likely to work for most European languages (including 
Russian) but doesn't seem particularly suitable for very language 
alphabet languages like Japanese and Chinese. The process described 
here is not (yet) fully automatic but the hand intervention required is 
small and may easily be done even by people with only a very little 
knowledge of the language being dealt with. </P
><P
>The process involves the following steps 
<P
></P
><UL
><LI
STYLE="list-style-type: disc"
><P
>&#13;Pre-processing lexicon into suitable training set </P
></LI
><LI
STYLE="list-style-type: disc"
><P
>&#13;Defining the set of allowable pairing of letters to phones. (We intend 
to do this fully automatically in future versions). </P
></LI
><LI
STYLE="list-style-type: disc"
><P
>&#13;Constructing the probabilities of each letter/phone pair. </P
></LI
><LI
STYLE="list-style-type: disc"
><P
>&#13;Aligning letters to an equal set of phones/_epsilons_. </P
></LI
><LI
STYLE="list-style-type: disc"
><P
>&#13;Extracting the data by letter suitable for training. </P
></LI
><LI
STYLE="list-style-type: disc"
><P
>&#13;Building CART models for predicting phone from letters (and context). </P
></LI
><LI
STYLE="list-style-type: disc"
><P
>&#13;Building additional lexical stress assignment model (if necessary). </P
></LI
></UL
>
All except the first two stages of this are fully automatic. </P
><P
>Before building a model its wise to think a little about what you want 
it to do. Ideally the model is an auxiliary to the lexicon so only 
words not found in the lexicon will require use of the letter-to-sound 
rules. Thus only unusual forms are likely to require the rules. More 
precisely the most common words, often having the most non-standard 
pronunciations, should probably be explicitly listed always. It is 
possible to reduce the size of the lexicon (sometimes drastically) by 
removing all entries that the training LTS model correctly predicts. </P
><P
>Before starting it is wise to consider removing some entries from the 
lexicon before training, I typically will remove words under 4 letters 
and if part of speech information is available I remove all function 
words, ideally only training from nouns verbs and adjectives as these 
are the most likely forms to be unknown in text. It is useful to have 
morphologically inflected and derived forms in the training set as it is 
often such variant forms that not found in the lexicon even though their 
root morpheme is. Note that in many forms of text, proper names are the 
most common form of unknown word and even the technique presented here 
may not adequately cater for that form of unknown words (especially if 
they unknown words are non-native names). This is all stating that this 
may or may not be appropriate for your task but the rules generated by 
this learning process have in the examples we've done been much better 
than what we could produce by hand writing rules of the form described 
in the previous section. </P
><P
>First preprocess the lexicon into a file of lexical entries to be used 
for training, removing functions words and changing the head words to 
all lower case (may be language dependent). The entries should be of 
the form used for input for Festival's lexicon compilation. Specifically 
the pronunciations should be simple lists of phones (no 
syllabification). Depending on the language, you may wish to remove the 
stressing---for examples here we have though later tests suggest that we 
should keep it in even for English. Thus the training set should look 
something like 
<A
NAME="AEN1492"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
CLASS="LITERALLAYOUT"
>("table"&nbsp;nil&nbsp;(t&nbsp;ei&nbsp;b&nbsp;l))<br>
("suspicious"&nbsp;nil&nbsp;(s&nbsp;@&nbsp;s&nbsp;p&nbsp;i&nbsp;sh&nbsp;@&nbsp;s))</P
></BLOCKQUOTE
>
It is best to split the data into a training set and a test set 
if you wish to know how well your training has worked. In our 
tests we remove every tenth entry and put it in a test set. Note this 
will mean our test results are probably better than if we removed 
say the last ten in every hundred. </P
><P
>The second stage is to define the set of allowable letter to phone 
mappings irrespective of context. This can sometimes be initially done 
by hand then checked against the training set. Initially construct a 
file of the form 
<A
NAME="AEN1495"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
CLASS="LITERALLAYOUT"
>(require&nbsp;'lts_build)<br>
(set!&nbsp;allowables&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'((a&nbsp;_epsilon_)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(b&nbsp;_epsilon_)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(c&nbsp;_epsilon_)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;...<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(y&nbsp;_epsilon_)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(z&nbsp;_epsilon_)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(#&nbsp;#)))</P
></BLOCKQUOTE
>
All letters that appear in the alphabet should (at least) map to 
<CODE
CLASS="VARNAME"
>_epsilon_</CODE
>, including any accented characters that appear in that 
language. Note the last two hashes. These are used by to denote 
beginning and end of word and are automatically added during training, 
they must appear in the list and should only map to themselves. </P
><P
>To incrementally add to this allowable list run festival as 
<A
NAME="AEN1499"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
CLASS="LITERALLAYOUT"
>festival&nbsp;allowables.scm&nbsp;</P
></BLOCKQUOTE
>
and at the prompt type 
<A
NAME="AEN1501"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
CLASS="LITERALLAYOUT"
>festival&#62;&nbsp;(cummulate-pairs&nbsp;"oald.train")</P
></BLOCKQUOTE
>
with your train file. This will print out each lexical entry 
that couldn't be aligned with the current set of allowables. At the 
start this will be every entry. Looking at these entries add 
to the allowables to make alignment work. For example if the 
following word fails 
<A
NAME="AEN1503"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
CLASS="LITERALLAYOUT"
>("abate"&nbsp;nil&nbsp;(ah&nbsp;b&nbsp;ey&nbsp;t))&nbsp;</P
></BLOCKQUOTE
>
Add <CODE
CLASS="VARNAME"
>ah</CODE
> to the allowables for letter <CODE
CLASS="VARNAME"
>a</CODE
>, <CODE
CLASS="VARNAME"
>b</CODE
> to 
<CODE
CLASS="VARNAME"
>b</CODE
>, <CODE
CLASS="VARNAME"
>ey</CODE
> to <CODE
CLASS="VARNAME"
>a</CODE
> and <CODE
CLASS="VARNAME"
>t</CODE
> to letter <CODE
CLASS="VARNAME"
>t</CODE
>. After 
doing that restart festival and call <CODE
CLASS="VARNAME"
>cummulate-pairs</CODE
> again. 
Incrementally add to the allowable pairs until the number of failures 
becomes acceptable. Often there are entries for which there is no real 
relationship between the letters and the pronunciation such as in 
abbreviations and foreign words (e.g. "aaa" as "t r ih p ax l ey"). For 
the lexicons I've used the technique on less than 10 per thousand fail 
in this way. </P
><P
>It is worth while being consistent on defining your set of allowables. 
(At least) two mappings are possible for the letter sequence 
<CODE
CLASS="VARNAME"
>ch}---havin</CODE
> letter <CODE
CLASS="VARNAME"
>c</CODE
> go to phone <CODE
CLASS="VARNAME"
>ch</CODE
> and letter 
<CODE
CLASS="VARNAME"
>h</CODE
> go to <CODE
CLASS="VARNAME"
>_epsilon_</CODE
> and also letter <CODE
CLASS="VARNAME"
>c</CODE
> go to phone 
<CODE
CLASS="VARNAME"
>_epsilon_</CODE
> and letter <CODE
CLASS="VARNAME"
>h</CODE
> goes to <CODE
CLASS="VARNAME"
>ch</CODE
>. However only 
one should be allowed, we preferred <CODE
CLASS="VARNAME"
>c</CODE
> to <CODE
CLASS="VARNAME"
>ch</CODE
>. </P
><P
>It may also be the case that some letters give rise to more than one 
phone. For example the letter <CODE
CLASS="VARNAME"
>x</CODE
> in English is often pronounced as 
the phone combination <CODE
CLASS="VARNAME"
>k</CODE
> and <CODE
CLASS="VARNAME"
>s</CODE
>. To allow this, use the 
multiphone <CODE
CLASS="VARNAME"
>k-s</CODE
>. Thus the multiphone <CODE
CLASS="VARNAME"
>k-s</CODE
> will be predicted 
for <CODE
CLASS="VARNAME"
>x</CODE
> in some context and the model will separate it into two 
phones while it also ignoring any predicted <CODE
CLASS="VARNAME"
>_epsilons_</CODE
>. Note that 
multiphone units are relatively rare but do occur. In English, letter 
<CODE
CLASS="VARNAME"
>x</CODE
> give rise to a few, <CODE
CLASS="VARNAME"
>k-s</CODE
> in <CODE
CLASS="VARNAME"
>taxi</CODE
>, <CODE
CLASS="VARNAME"
>g-s</CODE
> in 
<CODE
CLASS="VARNAME"
>example</CODE
>, and sometimes <CODE
CLASS="VARNAME"
>g-zh</CODE
> and <CODE
CLASS="VARNAME"
>k-sh</CODE
> in 
<CODE
CLASS="VARNAME"
>luxury</CODE
>. Others are <CODE
CLASS="VARNAME"
>w-ah</CODE
> in <CODE
CLASS="VARNAME"
>one</CODE
>, <CODE
CLASS="VARNAME"
>t-s</CODE
> in 
<CODE
CLASS="VARNAME"
>pizza</CODE
>, <CODE
CLASS="VARNAME"
>y-uw</CODE
> in <CODE
CLASS="VARNAME"
>new</CODE
> (British), <CODE
CLASS="VARNAME"
>ah-m</CODE
> in 
<CODE
CLASS="VARNAME"
>-ism</CODE
> etc. Three phone multiphone are much rarer but may exist, they 
are not supported by this code as is, but such entries should probably 
be ignored. Note the <CODE
CLASS="VARNAME"
>-</CODE
> sign in the multiphone examples is 
significant and is used to identify multiphones. </P
><P
>The allowables for OALD end up being 
<A
NAME="AEN1552"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
CLASS="LITERALLAYOUT"
>(set!&nbsp;allowables&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;((a&nbsp;_epsilon_&nbsp;ei&nbsp;aa&nbsp;a&nbsp;e@&nbsp;@&nbsp;oo&nbsp;au&nbsp;o&nbsp;i&nbsp;ou&nbsp;ai&nbsp;uh&nbsp;e)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(b&nbsp;_epsilon_&nbsp;b&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(c&nbsp;_epsilon_&nbsp;k&nbsp;s&nbsp;ch&nbsp;sh&nbsp;@-k&nbsp;s&nbsp;t-s)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(d&nbsp;_epsilon_&nbsp;d&nbsp;dh&nbsp;t&nbsp;jh)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(e&nbsp;_epsilon_&nbsp;@&nbsp;ii&nbsp;e&nbsp;e@&nbsp;i&nbsp;@@&nbsp;i@&nbsp;uu&nbsp;y-uu&nbsp;ou&nbsp;ei&nbsp;aa&nbsp;oi&nbsp;y&nbsp;y-u@&nbsp;o)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(f&nbsp;_epsilon_&nbsp;f&nbsp;v&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(g&nbsp;_epsilon_&nbsp;g&nbsp;jh&nbsp;zh&nbsp;th&nbsp;f&nbsp;ng&nbsp;k&nbsp;t)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(h&nbsp;_epsilon_&nbsp;h&nbsp;@&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(i&nbsp;_epsilon_&nbsp;i@&nbsp;i&nbsp;@&nbsp;ii&nbsp;ai&nbsp;@@&nbsp;y&nbsp;ai-@&nbsp;aa&nbsp;a)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(j&nbsp;_epsilon_&nbsp;h&nbsp;zh&nbsp;jh&nbsp;i&nbsp;y&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(k&nbsp;_epsilon_&nbsp;k&nbsp;ch&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(l&nbsp;_epsilon_&nbsp;l&nbsp;@-l&nbsp;l-l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(m&nbsp;_epsilon_&nbsp;m&nbsp;@-m&nbsp;n)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(n&nbsp;_epsilon_&nbsp;n&nbsp;ng&nbsp;n-y&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(o&nbsp;_epsilon_&nbsp;@&nbsp;ou&nbsp;o&nbsp;oo&nbsp;uu&nbsp;u&nbsp;au&nbsp;oi&nbsp;i&nbsp;@@&nbsp;e&nbsp;uh&nbsp;w&nbsp;u@&nbsp;w-uh&nbsp;y-@)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(p&nbsp;_epsilon_&nbsp;f&nbsp;p&nbsp;v&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(q&nbsp;_epsilon_&nbsp;k&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(r&nbsp;_epsilon_&nbsp;r&nbsp;@@&nbsp;@-r)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(s&nbsp;_epsilon_&nbsp;z&nbsp;s&nbsp;sh&nbsp;zh&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(t&nbsp;_epsilon_&nbsp;t&nbsp;th&nbsp;sh&nbsp;dh&nbsp;ch&nbsp;d&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(u&nbsp;_epsilon_&nbsp;uu&nbsp;@&nbsp;w&nbsp;@@&nbsp;u&nbsp;uh&nbsp;y-uu&nbsp;u@&nbsp;y-u@&nbsp;y-u&nbsp;i&nbsp;y-uh&nbsp;y-@&nbsp;e)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(v&nbsp;_epsilon_&nbsp;v&nbsp;f&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(w&nbsp;_epsilon_&nbsp;w&nbsp;uu&nbsp;v&nbsp;f&nbsp;u)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(x&nbsp;_epsilon_&nbsp;k-s&nbsp;g-z&nbsp;sh&nbsp;z&nbsp;k-sh&nbsp;z&nbsp;g-zh&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(y&nbsp;_epsilon_&nbsp;i&nbsp;ii&nbsp;i@&nbsp;ai&nbsp;uh&nbsp;y&nbsp;@&nbsp;ai-@)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(z&nbsp;_epsilon_&nbsp;z&nbsp;t-s&nbsp;s&nbsp;zh&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(#&nbsp;#)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;))</P
></BLOCKQUOTE
>
Note this is an exhaustive list and (deliberately) says nothing 
about the contexts or frequency that these letter to phone pairs appear. 
That information will be generated automatically from the training 
set. </P
><P
>Once the number of failed matches is significantly low enough 
let <CODE
CLASS="VARNAME"
>cummulate-pairs</CODE
> run to completion. This counts the number 
of times each letter/phone pair occurs in allowable alignments. </P
><P
>Next call 
<A
NAME="AEN1557"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
CLASS="LITERALLAYOUT"
>festival&#62;&nbsp;(save-table&nbsp;"oald-")</P
></BLOCKQUOTE
>
with the name of your lexicon. This changes the cumulation 
table into probabilities and saves it. </P
><P
>Restart festival loading this new table 
<A
NAME="AEN1560"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
CLASS="LITERALLAYOUT"
>festival&nbsp;allowables.scm&nbsp;oald-pl-table.scm</P
></BLOCKQUOTE
>
Now each word can be aligned to an equally-lengthed string of phones, 
epsilon and multiphones. 
<A
NAME="AEN1562"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
CLASS="LITERALLAYOUT"
>festival&#62;&nbsp;(aligndata&nbsp;"oald.train"&nbsp;"oald.train.align")</P
></BLOCKQUOTE
>
Do this also for you test set. </P
><P
>This will produce entries like 
<A
NAME="AEN1565"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
CLASS="LITERALLAYOUT"
>aaronson&nbsp;_epsilon_&nbsp;aa&nbsp;r&nbsp;ah&nbsp;n&nbsp;s&nbsp;ah&nbsp;n<br>
abandon&nbsp;ah&nbsp;b&nbsp;ae&nbsp;n&nbsp;d&nbsp;ah&nbsp;n<br>
abate&nbsp;ah&nbsp;b&nbsp;ey&nbsp;t&nbsp;_epsilon_<br>
abbe&nbsp;ae&nbsp;b&nbsp;_epsilon_&nbsp;iy</P
></BLOCKQUOTE
></P
><P
>The next stage is to build features suitable for <TT
CLASS="FILENAME"
>wagon</TT
> to 
build models. This is done by 
<A
NAME="AEN1569"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
CLASS="LITERALLAYOUT"
>festival&#62;&nbsp;(build-feat-file&nbsp;"oald.train.align"&nbsp;"oald.train.feats")</P
></BLOCKQUOTE
>
Again the same for the test set. </P
><P
>Now you 
need to construct a description file for <TT
CLASS="FILENAME"
>wagon</TT
> for 
the given data. The can be done using the script <TT
CLASS="FILENAME"
>make_wgn_desc</TT
> 
provided with the speech tools </P
><P
>Here is an example script for building the models, you will need 
to modify it for your particular database but it shows the basic 
processes 
<A
NAME="AEN1575"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
CLASS="LITERALLAYOUT"
>for&nbsp;i&nbsp;in&nbsp;a&nbsp;b&nbsp;c&nbsp;d&nbsp;e&nbsp;f&nbsp;g&nbsp;h&nbsp;i&nbsp;j&nbsp;k&nbsp;l&nbsp;m&nbsp;n&nbsp;o&nbsp;p&nbsp;q&nbsp;r&nbsp;s&nbsp;t&nbsp;u&nbsp;v&nbsp;w&nbsp;x&nbsp;y&nbsp;z&nbsp;<br>
do<br>
&nbsp;&nbsp;&nbsp;#&nbsp;Stop&nbsp;value&nbsp;for&nbsp;wagon<br>
&nbsp;&nbsp;&nbsp;STOP=2<br>
&nbsp;&nbsp;&nbsp;echo&nbsp;letter&nbsp;$i&nbsp;STOP&nbsp;$STOP<br>
&nbsp;&nbsp;&nbsp;#&nbsp;Find&nbsp;training&nbsp;set&nbsp;for&nbsp;letter&nbsp;$i<br>
&nbsp;&nbsp;&nbsp;cat&nbsp;oald.train.feats&nbsp;|<br>
&nbsp;&nbsp;&nbsp;&nbsp;awk&nbsp;'{if&nbsp;($6&nbsp;==&nbsp;"'$i'")&nbsp;print&nbsp;$0}'&nbsp;&#62;ltsdataTRAIN.$i.feats<br>
&nbsp;&nbsp;&nbsp;#&nbsp;split&nbsp;training&nbsp;set&nbsp;to&nbsp;get&nbsp;heldout&nbsp;data&nbsp;for&nbsp;stepwise&nbsp;testing<br>
&nbsp;&nbsp;&nbsp;traintest&nbsp;ltsdataTRAIN.$i.feats<br>
&nbsp;&nbsp;&nbsp;#&nbsp;Extract&nbsp;test&nbsp;data&nbsp;for&nbsp;letter&nbsp;$i<br>
&nbsp;&nbsp;&nbsp;cat&nbsp;oald.test.feats&nbsp;|<br>
&nbsp;&nbsp;&nbsp;&nbsp;awk&nbsp;'{if&nbsp;($6&nbsp;==&nbsp;"'$i'")&nbsp;print&nbsp;$0}'&nbsp;&#62;ltsdataTEST.$i.feats<br>
&nbsp;&nbsp;&nbsp;#&nbsp;run&nbsp;wagon&nbsp;to&nbsp;predict&nbsp;model<br>
&nbsp;&nbsp;&nbsp;wagon&nbsp;-data&nbsp;ltsdataTRAIN.$i.feats.train&nbsp;-test&nbsp;ltsdataTRAIN.$i.feats.test&nbsp;\<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-stepwise&nbsp;-desc&nbsp;ltsOALD.desc&nbsp;-stop&nbsp;$STOP&nbsp;-output&nbsp;lts.$i.tree<br>
&nbsp;&nbsp;&nbsp;#&nbsp;Test&nbsp;the&nbsp;resulting&nbsp;tree&nbsp;against<br>
&nbsp;&nbsp;&nbsp;wagon_test&nbsp;-heap&nbsp;2000000&nbsp;-data&nbsp;ltsdataTEST.$i.feats&nbsp;-desc&nbsp;ltsOALD.desc&nbsp;\<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-tree&nbsp;lts.$i.tree<br>
done</P
></BLOCKQUOTE
>
The script <TT
CLASS="FILENAME"
>traintest</TT
> splits the given file <TT
CLASS="FILENAME"
>X</TT
> into <TT
CLASS="FILENAME"
>X.train</TT
> 
and <TT
CLASS="FILENAME"
>X.test</TT
> with every tenth line in <TT
CLASS="FILENAME"
>X.test</TT
> and the rest 
in <TT
CLASS="FILENAME"
>X.train</TT
>. </P
><P
>This script can take a significant amount of time to run, about 6 hours 
on a Sun Ultra 140. </P
><P
>Once the models are created the must be collected together into 
a single list structure. The trees generated by <TT
CLASS="FILENAME"
>wagon</TT
> 
contain fully probability distributions at each leaf, at this time 
this information can be removed as only the most probable will 
actually be predicted. This substantially reduces the size of the 
tress. 
<A
NAME="AEN1586"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
CLASS="LITERALLAYOUT"
>(merge_models&nbsp;'oald_lts_rules&nbsp;"oald_lts_rules.scm"&nbsp;allowables)</P
></BLOCKQUOTE
>
(<TT
CLASS="FILENAME"
>merge_models</TT
> is defined within 
<TT
CLASS="FILENAME"
>lts_build.scm</TT
> 
The given file will contain a <CODE
CLASS="VARNAME"
>set!</CODE
> for the given variable 
name to an assoc list of letter to trained tree. Note the above 
function naively assumes that the letters in the alphabet are 
the 26 lower case letters of the English alphabet, you will need 
to edit this adding accented letters if required. Note that 
adding "'" (single quote) as a letter is a little tricky in scheme 
but can be done---the command <CODE
CLASS="VARNAME"
>(intern "'")</CODE
> will give you 
the symbol for single quote. </P
><P
>To test a set of lts models load the saved model and call 
the following function with the test align file 
<A
NAME="AEN1593"
></A
><BLOCKQUOTE
CLASS="BLOCKQUOTE"
><P
CLASS="LITERALLAYOUT"
>festival&nbsp;oald-table.scm&nbsp;oald_lts_rules.scm<br>
festival&#62;&nbsp;(lts_testset&nbsp;"oald.test.align"&nbsp;oald_lts_rules)</P
></BLOCKQUOTE
>
The result (after showing all the failed ones), will be a table showing 
the results for each letter, for all letters and for complete words. 
The failed entries may give some notion of how good or bad the result 
is, sometimes it will be simple vowel differences, long versus short, 
schwa versus full vowel, other times it may be who consonants missing. 
Remember the ultimate quality of the letter sound rules is how adequate 
they are at providing <I
CLASS="EMPHASIS"
>acceptable</I
> pronunciations rather than 
how good the numeric score is. </P
><P
>&#13;
For some languages (e.g. English) it is necessary to also find a 
stress pattern for unknown words. Ultimately for this to work well 
you need to know the morphological decomposition of the word. 
At present we provide a CART trained system to predict stress 
patterns for English. If does get 94.6% correct for an unseen test 
set but that isn't really very good. Later tests suggest that 
predicting stressed and unstressed phones directly is actually 
better for getting whole words correct even though the models 
do slightly worse on a per phone basis [<SPAN
CLASS="CITATION"
>black98b</SPAN
>]. </P
><P
>&#13;

As the lexicon may be a large part of the system we have also 
experimented with removing entries from the lexicon if the letter to 
sound rules system (and stress assignment system) can correct predict 
them. For OALD this allows us to half the size of the lexicon, it could 
possibly allow more if a certain amount of fuzzy acceptance was allowed 
(e.g. with schwa). For other languages the gain here can be very 
significant, for German and French we can reduce the lexicon by over 90%. 
The function <CODE
CLASS="VARNAME"
>reduce_lexicon</CODE
> in <TT
CLASS="FILENAME"
>festival/lib/lts_build.scm</TT
> 
was used to do this. A discussion of using the above technique as a 
dictionary compression method is discussed in [<SPAN
CLASS="CITATION"
>pagel98</SPAN
>]. A 
morphological decomposition algorithm, like that described in 
[<SPAN
CLASS="CITATION"
>black91</SPAN
>], may even help more. </P
><P
>The technique described in this section and its relative merits with 
respect to a number of languages/lexicons and tasks is discussed more 
fully in [<SPAN
CLASS="CITATION"
>black98b</SPAN
>]. </P
></DIV
><DIV
CLASS="NAVFOOTER"
><HR
ALIGN="LEFT"
WIDTH="100%"><TABLE
SUMMARY="Footer navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
><A
HREF="x1429.html"
ACCESSKEY="P"
>&#60;&#60;&#60; Previous</A
></TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="book1.html"
ACCESSKEY="H"
>Home</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
><A
HREF="x1615.html"
ACCESSKEY="N"
>Next &#62;&#62;&#62;</A
></TD
></TR
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
>Building letter-to-sound rules by hand</TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="c1379.html"
ACCESSKEY="U"
>Up</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
>Post-lexical rules</TD
></TR
></TABLE
></DIV
></BODY
></HTML
>